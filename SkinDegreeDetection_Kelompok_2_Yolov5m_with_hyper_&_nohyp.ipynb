{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4kOnmogjwHh"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install IPython\n",
        "!pip install tqdm --upgrade\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks\n",
        "\n",
        "\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"TrtsulMFTYFCbO2hrWJg\")\n",
        "project = rf.workspace(\"binussss\").project(\"burn-wound-classification\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "23Wp21-Dj54M",
        "outputId": "cf77761d-e8ec-4299-92f0-30bd7ef1c657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-163-g016e046 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 23.5/78.2 GB disk)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.8-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.7.0.72)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting idna==2.10\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (8.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.15)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.39.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=29314fa5e5ccf8985f7d77b334ac2f48fc322ed668348e12dec7910183c35448\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.0.8 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in burn-wound-classification-1 to yolov5pytorch: 100% [244686177 / 244686177] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to burn-wound-classification-1 in yolov5pytorch:: 100%|██████████| 21914/21914 [00:04<00:00, 4664.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMnaeWcnkCf2",
        "outputId": "674519f0-2154-4692-b977-68b1f7804df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter evolve"
      ],
      "metadata": {
        "id": "oMbF5E-7v4O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data '/content/yolov5/burn-wound-classification-1/data.yaml' --img 640 --batch 16 --epochs 6 --weights yolov5m.pt --cache --evolve --project \"/content/drive/MyDrive/Yolov5m_hyper\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEAvAN7BkI-p",
        "outputId": "921003b1-2824-4411-f6d8-d687d70073c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-08 06:54:14.404948: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-08 06:54:15.315158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=/content/yolov5/burn-wound-classification-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=6, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=300, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/Yolov5m_hyper, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-134-g23c4923 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n",
            "100% 40.8M/40.8M [00:00<00:00, 182MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 10.3/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9943: 100% 1000/1000 [00:03<00:00, 265.76it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.994-mean/best, past_thr=0.656-mean: 60,67, 97,148, 167,233, 288,283, 311,333, 534,451, 457,582, 627,636, 639,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      6.15G    0.04587    0.04124    0.03532         49        640: 100% 627/627 [05:16<00:00,  1.98it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      6.15G    0.02887    0.02173    0.03284         50        640: 100% 627/627 [05:12<00:00,  2.00it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      6.15G    0.02325      0.017    0.02914         53        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      6.15G    0.01685    0.01429    0.02741         44        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      6.15G    0.01443    0.01331    0.02639         44        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      6.15G    0.01028    0.01131    0.02519         52        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.33it/s]\n",
            "                   all        457        457      0.622      0.763      0.722      0.718\n",
            "\n",
            "6 epochs completed in 0.519 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m1 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.62182,               0.7633,              0.72225,              0.71767,            0.0048726,            0.0064903,             0.026748,                 0.01,                 0.01,                0.937,               0.0005,                    3,                  0.8,                  0.1,                 0.05,                  0.5,                    1,                    1,                    1,                  0.2,                    4,                    0,                0.015,                  0.7,                  0.4,                    0,                  0.1,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.93811, weight_decay=0.00053, warmup_epochs=2.92797, warmup_momentum=0.80347, warmup_bias_lr=0.10067, box=0.05124, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=0.99325, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.01492, hsv_s=0.69252, hsv_v=0.389, degrees=0.0, translate=0.09782, scale=0.48466, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.14315\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=3.14315\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00053), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.5/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9943: 100% 1000/1000 [00:03<00:00, 262.73it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.994-mean/best, past_thr=0.656-mean: 60,67, 97,148, 167,233, 288,283, 311,333, 534,451, 457,582, 627,636, 639,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      6.15G    0.04716     0.0411    0.03536         50        640: 100% 627/627 [05:14<00:00,  1.99it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      6.15G    0.02937    0.02165    0.03317         50        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      6.15G    0.02386    0.01681     0.0293         53        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      6.15G    0.01963    0.01521    0.02776         44        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      6.15G    0.01382    0.01296    0.02646         45        640: 100% 627/627 [05:06<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      6.15G   0.009883    0.01097    0.02511         52        640: 100% 627/627 [05:06<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.14it/s]\n",
            "                   all        457        457      0.636      0.713      0.746      0.724\n",
            "\n",
            "6 epochs completed in 0.517 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m2 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.63629,              0.71262,              0.74596,               0.7236,            0.0068835,            0.0062894,             0.024872,                 0.01,                 0.01,              0.93811,              0.00053,                2.928,              0.80347,              0.10067,              0.05124,                  0.5,                    1,                    1,              0.99325,                  0.2,                    4,                    0,              0.01492,              0.69252,                0.389,                    0,              0.09782,              0.48466,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.1431\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01082, momentum=0.95707, weight_decay=0.00056, warmup_epochs=2.928, warmup_momentum=0.77454, warmup_bias_lr=0.09365, box=0.05124, cls=0.5251, cls_pw=0.9799, obj=1.00782, obj_pw=0.92876, iou_t=0.2, anchor_t=3.98836, fl_gamma=0.0, hsv_h=0.01348, hsv_s=0.70566, hsv_v=0.389, degrees=0.0, translate=0.09782, scale=0.47043, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.29207\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.29207\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     21552  models.yolo.Detect                      [3, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20868624 parameters, 20868624 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00056), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.4/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9926: 100% 1000/1000 [00:03<00:00, 322.67it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 5.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.672/0.993-mean/best, past_thr=0.784-mean: 70,146, 206,263, 550,506, 537,574, 640,640, 657,636\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      5.97G    0.04969    0.04137    0.03637         50        640: 100% 627/627 [05:14<00:00,  1.99it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      5.97G     0.0321     0.0219    0.03302         50        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      5.97G    0.02445    0.01687    0.02929         53        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      5.97G    0.01914    0.01536     0.0288         43        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      5.97G    0.01302    0.01279    0.02758         45        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      5.97G   0.009145    0.01072    0.02639         52        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.43it/s]\n",
            "                   all        457        457      0.631      0.755      0.733      0.728\n",
            "\n",
            "6 epochs completed in 0.519 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m3 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.63051,              0.75516,              0.73257,              0.72843,            0.0048442,             0.006727,             0.025846,                 0.01,              0.01082,              0.95707,              0.00056,                2.928,              0.77454,              0.09365,              0.05124,               0.5251,               0.9799,               1.0078,              0.92876,                  0.2,               3.9884,                    0,              0.01348,              0.70566,                0.389,                    0,              0.09782,              0.47043,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.2921\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0099, lrf=0.01, momentum=0.93811, weight_decay=0.00052, warmup_epochs=3.15604, warmup_momentum=0.79799, warmup_bias_lr=0.08783, box=0.06543, cls=0.52297, cls_pw=0.9714, obj=0.98803, obj_pw=1.08566, iou_t=0.2, anchor_t=4.4505, fl_gamma=0.0, hsv_h=0.01616, hsv_s=0.73913, hsv_v=0.51056, degrees=0.0, translate=0.09899, scale=0.46777, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     21552  models.yolo.Detect                      [3, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20868624 parameters, 20868624 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0099) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00052), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.4/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9926: 100% 1000/1000 [00:04<00:00, 201.87it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.672/0.993-mean/best, past_thr=0.784-mean: 70,146, 206,263, 550,506, 537,574, 640,640, 657,636\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      5.96G    0.06262     0.0484    0.03618         50        640: 100% 627/627 [05:17<00:00,  1.97it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      5.96G     0.0395    0.02564    0.03421         50        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      5.96G    0.03186    0.01887    0.03065         53        640: 100% 627/627 [05:13<00:00,  2.00it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      5.96G    0.02316    0.01596     0.0287         43        640: 100% 627/627 [05:06<00:00,  2.05it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      5.96G    0.01988    0.01484    0.02763         45        640: 100% 627/627 [05:04<00:00,  2.06it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      5.96G    0.01383    0.01257    0.02636         52        640: 100% 627/627 [05:05<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.44it/s]\n",
            "                   all        457        457      0.629      0.764      0.738      0.735\n",
            "\n",
            "6 epochs completed in 0.517 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m4 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.62945,              0.76354,              0.73793,              0.73522,            0.0095635,            0.0061869,             0.025438,               0.0099,                 0.01,              0.93811,              0.00052,                3.156,              0.79799,              0.08783,              0.06543,              0.52297,               0.9714,              0.98803,               1.0857,                  0.2,               4.4505,                    0,              0.01616,              0.73913,              0.51056,                    0,              0.09899,              0.46777,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    2\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0087, lrf=0.01197, momentum=0.96714, weight_decay=0.00056, warmup_epochs=2.60053, warmup_momentum=0.64108, warmup_bias_lr=0.07335, box=0.05037, cls=0.5251, cls_pw=1.08087, obj=1.02643, obj_pw=0.82256, iou_t=0.2, anchor_t=4.21665, fl_gamma=0.0, hsv_h=0.01348, hsv_s=0.63217, hsv_v=0.35605, degrees=0.0, translate=0.10666, scale=0.50633, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.7514\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.7514\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0087) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00056), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.6/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9943: 100% 1000/1000 [00:04<00:00, 234.30it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.994-mean/best, past_thr=0.656-mean: 60,67, 97,148, 167,233, 288,283, 311,333, 534,451, 457,582, 627,636, 639,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      6.15G    0.05243    0.04242    0.03945         50        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      6.15G    0.03114    0.02497     0.0365         50        640: 100% 627/627 [05:04<00:00,  2.06it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      6.15G    0.02362    0.01711    0.03202         53        640: 100% 627/627 [05:03<00:00,  2.07it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      6.15G    0.01639    0.01497    0.03068         43        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      6.15G    0.01139    0.01225     0.0292         44        640: 100% 627/627 [05:02<00:00,  2.07it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      6.15G   0.008177    0.01076    0.02814         52        640: 100% 627/627 [05:02<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  1.96it/s]\n",
            "                   all        457        457      0.608      0.748      0.738      0.709\n",
            "\n",
            "6 epochs completed in 0.510 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m5 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.60774,              0.74829,              0.73835,              0.70884,            0.0069145,            0.0060416,             0.027612,               0.0087,              0.01197,              0.96714,              0.00056,               2.6005,              0.64108,              0.07335,              0.05037,               0.5251,               1.0809,               1.0264,              0.82256,                  0.2,               4.2166,                    0,              0.01348,              0.63217,              0.35605,                    0,              0.10666,              0.50633,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.7514\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00999, lrf=0.01, momentum=0.93679, weight_decay=0.00054, warmup_epochs=2.91701, warmup_momentum=0.81977, warmup_bias_lr=0.10067, box=0.05094, cls=0.48498, cls_pw=0.99548, obj=1.00608, obj_pw=1.02384, iou_t=0.2, anchor_t=4.02627, fl_gamma=0.0, hsv_h=0.01519, hsv_s=0.67744, hsv_v=0.3905, degrees=0.0, translate=0.09597, scale=0.48479, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.1431\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=3.1431\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00999) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00054), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.5/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9943: 100% 1000/1000 [00:03<00:00, 279.38it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.994-mean/best, past_thr=0.656-mean: 60,67, 97,148, 167,233, 288,283, 311,333, 534,451, 457,582, 627,636, 639,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      6.16G    0.04561    0.04094    0.03418         50        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      6.16G    0.02876    0.02098    0.03228         50        640: 100% 627/627 [05:04<00:00,  2.06it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      6.16G    0.02312    0.01702    0.02858         53        640: 100% 627/627 [05:03<00:00,  2.07it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      6.16G    0.01934     0.0154    0.02684         44        640: 100% 627/627 [05:02<00:00,  2.07it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      6.16G    0.01367    0.01306    0.02566         45        640: 100% 627/627 [05:02<00:00,  2.07it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      6.16G     0.0096    0.01112    0.02439         52        640: 100% 627/627 [05:06<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.42it/s]\n",
            "                   all        457        457      0.573      0.791      0.734      0.725\n",
            "\n",
            "6 epochs completed in 0.510 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m6 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.57298,              0.79137,              0.73433,              0.72514,            0.0061112,            0.0075869,              0.02604,              0.00999,                 0.01,              0.93679,              0.00054,                2.917,              0.81977,              0.10067,              0.05094,              0.48498,              0.99548,               1.0061,               1.0238,                  0.2,               4.0263,                    0,              0.01519,              0.67744,               0.3905,                    0,              0.09597,              0.48479,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.1431\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00999, lrf=0.01003, momentum=0.93679, weight_decay=0.00054, warmup_epochs=2.94831, warmup_momentum=0.81634, warmup_bias_lr=0.10049, box=0.05095, cls=0.49401, cls_pw=0.98947, obj=1.00847, obj_pw=1.00536, iou_t=0.2, anchor_t=4.09102, fl_gamma=0.0, hsv_h=0.01505, hsv_s=0.67744, hsv_v=0.3905, degrees=0.0, translate=0.09547, scale=0.48973, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.9847, mixup=0.0, copy_paste=0.0, anchors=3.15274\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=3.15274\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00999) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00054), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.5/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9943: 100% 1000/1000 [00:04<00:00, 220.68it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.994-mean/best, past_thr=0.656-mean: 60,67, 97,148, 167,233, 288,283, 311,333, 534,451, 457,582, 627,636, 639,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      6.14G    0.04624    0.04093    0.03466         43        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      6.14G      0.029    0.02139     0.0324         49        640: 100% 627/627 [05:09<00:00,  2.02it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      6.14G    0.02325    0.01734    0.02905         53        640: 100% 627/627 [05:02<00:00,  2.07it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      6.14G    0.01952    0.01576    0.02759         44        640: 100% 627/627 [05:00<00:00,  2.09it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      6.14G    0.01382    0.01298    0.02623         53        640: 100% 627/627 [05:01<00:00,  2.08it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      6.14G   0.009756    0.01126    0.02492         46        640: 100% 627/627 [05:02<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.20it/s]\n",
            "                   all        457        457       0.65      0.792      0.763      0.742\n",
            "\n",
            "6 epochs completed in 0.509 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m7 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.65012,              0.79224,              0.76308,               0.7416,            0.0058449,            0.0067187,             0.022587,              0.00999,              0.01003,              0.93679,              0.00054,               2.9483,              0.81634,              0.10049,              0.05095,              0.49401,              0.98947,               1.0085,               1.0054,                  0.2,                4.091,                    0,              0.01505,              0.67744,               0.3905,                    0,              0.09547,              0.48973,                    0,                    0,                    0,                  0.5,               0.9847,                    0,                    0,               3.1527\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00987, lrf=0.01001, momentum=0.9379, weight_decay=0.00052, warmup_epochs=3.15176, warmup_momentum=0.79799, warmup_bias_lr=0.08778, box=0.06548, cls=0.52297, cls_pw=0.97333, obj=0.99058, obj_pw=1.0859, iou_t=0.2, anchor_t=4.44494, fl_gamma=0.0, hsv_h=0.0162, hsv_s=0.73944, hsv_v=0.51053, degrees=0.0, translate=0.09903, scale=0.46929, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     21552  models.yolo.Detect                      [3, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20868624 parameters, 20868624 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00987) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00052), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.5/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9926: 100% 1000/1000 [00:03<00:00, 301.58it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.672/0.993-mean/best, past_thr=0.784-mean: 70,146, 206,263, 550,506, 537,574, 640,640, 657,636\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      5.96G    0.06235    0.04819    0.03622         50        640: 100% 627/627 [05:15<00:00,  1.99it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      5.96G    0.03955    0.02548    0.03439         50        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      5.96G    0.03177    0.01896      0.031         53        640: 100% 627/627 [05:04<00:00,  2.06it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      5.96G    0.02296    0.01593    0.02861         43        640: 100% 627/627 [05:04<00:00,  2.06it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      5.96G    0.01981    0.01472    0.02751         45        640: 100% 627/627 [05:06<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      5.96G    0.01387    0.01253    0.02648         52        640: 100% 627/627 [05:03<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  1.99it/s]\n",
            "                   all        457        457      0.623      0.754      0.742      0.739\n",
            "\n",
            "6 epochs completed in 0.514 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m8 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.62301,              0.75412,              0.74248,              0.73874,            0.0073346,            0.0067923,             0.025172,              0.00987,              0.01001,               0.9379,              0.00052,               3.1518,              0.79799,              0.08778,              0.06548,              0.52297,              0.97333,              0.99058,               1.0859,                  0.2,               4.4449,                    0,               0.0162,              0.73944,              0.51053,                    0,              0.09903,              0.46929,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    2\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0104, lrf=0.01008, momentum=0.94049, weight_decay=0.00053, warmup_epochs=3.61369, warmup_momentum=0.8529, warmup_bias_lr=0.08915, box=0.06389, cls=0.53344, cls_pw=1.01007, obj=1.0629, obj_pw=1.12493, iou_t=0.2, anchor_t=4.23802, fl_gamma=0.0, hsv_h=0.01697, hsv_s=0.72336, hsv_v=0.52734, degrees=0.0, translate=0.09903, scale=0.43299, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.88371, mixup=0.0, copy_paste=0.0, anchors=2.17552\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.17552\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     21552  models.yolo.Detect                      [3, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20868624 parameters, 20868624 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0104) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00053), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.4/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9926: 100% 1000/1000 [00:03<00:00, 266.25it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 5.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.672/0.993-mean/best, past_thr=0.784-mean: 70,146, 206,263, 550,506, 537,574, 640,640, 657,636\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      5.97G    0.05774     0.0459    0.03753         46        640: 100% 627/627 [04:57<00:00,  2.11it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      5.97G    0.03627    0.02306    0.03446         47        640: 100% 627/627 [04:55<00:00,  2.12it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      5.97G    0.02947    0.01792    0.03102         55        640: 100% 627/627 [04:51<00:00,  2.15it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      5.97G    0.02258    0.01567    0.02959         43        640: 100% 627/627 [04:50<00:00,  2.16it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      5.97G    0.01948    0.01475    0.02855         51        640: 100% 627/627 [04:50<00:00,  2.16it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      5.97G     0.0136    0.01247    0.02739         39        640: 100% 627/627 [04:50<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  1.93it/s]\n",
            "                   all        457        457      0.634       0.74      0.734      0.718\n",
            "\n",
            "6 epochs completed in 0.490 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m9 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.63379,              0.74019,              0.73399,              0.71831,            0.0062534,            0.0071921,              0.02708,               0.0104,              0.01008,              0.94049,              0.00053,               3.6137,               0.8529,              0.08915,              0.06389,              0.53344,               1.0101,               1.0629,               1.1249,                  0.2,                4.238,                    0,              0.01697,              0.72336,              0.52734,                    0,              0.09903,              0.43299,                    0,                    0,                    0,                  0.5,              0.88371,                    0,                    0,               2.1755\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00976, lrf=0.01007, momentum=0.95444, weight_decay=0.0005, warmup_epochs=3.1518, warmup_momentum=0.79799, warmup_bias_lr=0.08778, box=0.06665, cls=0.50289, cls_pw=1.01536, obj=0.94971, obj_pw=1.06905, iou_t=0.2, anchor_t=4.65093, fl_gamma=0.0, hsv_h=0.01536, hsv_s=0.75625, hsv_v=0.51053, degrees=0.0, translate=0.09643, scale=0.48705, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.94885, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     21552  models.yolo.Detect                      [3, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20868624 parameters, 20868624 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00976) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.4/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9926: 100% 1000/1000 [00:03<00:00, 309.43it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.672/0.993-mean/best, past_thr=0.784-mean: 70,146, 206,263, 550,506, 537,574, 640,640, 657,636\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      5.97G     0.0637    0.04619    0.03576         46        640: 100% 627/627 [05:05<00:00,  2.05it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      5.97G    0.03964    0.02463    0.03381         46        640: 100% 627/627 [04:59<00:00,  2.09it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      5.97G     0.0319    0.01789     0.0304         38        640: 100% 627/627 [05:00<00:00,  2.09it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      5.97G    0.02242    0.01544    0.02865         51        640: 100% 627/627 [04:58<00:00,  2.10it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      5.97G    0.01888    0.01422    0.02775         47        640: 100% 627/627 [04:59<00:00,  2.09it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      5.97G    0.01325    0.01205     0.0265         46        640: 100% 627/627 [05:00<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.41it/s]\n",
            "                   all        457        457      0.644      0.772       0.74      0.734\n",
            "\n",
            "6 epochs completed in 0.503 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m10 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.64399,              0.77173,              0.74017,               0.7341,            0.0064928,            0.0058931,             0.025117,              0.00976,              0.01007,              0.95444,               0.0005,               3.1518,              0.79799,              0.08778,              0.06665,              0.50289,               1.0154,              0.94971,               1.0691,                  0.2,               4.6509,                    0,              0.01536,              0.75625,              0.51053,                    0,              0.09643,              0.48705,                    0,                    0,                    0,                  0.5,              0.94885,                    0,                    0,                    2\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01134, lrf=0.01113, momentum=0.95547, weight_decay=0.00052, warmup_epochs=3.63779, warmup_momentum=0.79799, warmup_bias_lr=0.08783, box=0.07874, cls=0.56148, cls_pw=1.02167, obj=1.20218, obj_pw=1.0857, iou_t=0.2, anchor_t=4.18029, fl_gamma=0.0, hsv_h=0.01632, hsv_s=0.9, hsv_v=0.52892, degrees=0.0, translate=0.09921, scale=0.45592, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.75634, mixup=0.0, copy_paste=0.0, anchors=2.69189\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.69189\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01134) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00052), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.3/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9943: 100% 1000/1000 [00:03<00:00, 255.88it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.994-mean/best, past_thr=0.656-mean: 60,67, 97,148, 167,233, 288,283, 311,333, 534,451, 457,582, 627,636, 639,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      6.16G    0.07273    0.05032     0.0406         39        640: 100% 627/627 [04:47<00:00,  2.18it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      6.16G    0.04231    0.02711    0.03891         33        640: 100% 627/627 [04:41<00:00,  2.23it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      6.16G    0.03443    0.01976    0.03761         44        640: 100% 627/627 [04:38<00:00,  2.25it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      6.16G    0.02711    0.01744    0.03452         36        640: 100% 627/627 [04:37<00:00,  2.26it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/5      6.16G    0.02268    0.01632    0.03284         39        640: 100% 627/627 [04:38<00:00,  2.25it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/5      6.16G    0.01558    0.01357     0.0318         36        640: 100% 627/627 [04:38<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.02it/s]\n",
            "                   all        457        457      0.635       0.74       0.72      0.676\n",
            "\n",
            "6 epochs completed in 0.469 hours.\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m11 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.63453,              0.73964,              0.71955,              0.67567,            0.0088124,            0.0075272,             0.031081,              0.01134,              0.01113,              0.95547,              0.00052,               3.6378,              0.79799,              0.08783,              0.07874,              0.56148,               1.0217,               1.2022,               1.0857,                  0.2,               4.1803,                    0,              0.01632,                  0.9,              0.52892,                    0,              0.09921,              0.45592,                    0,                    0,                    0,                  0.5,              0.75634,                    0,                    0,               2.6919\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00965, lrf=0.01051, momentum=0.9326, weight_decay=0.00048, warmup_epochs=3.1733, warmup_momentum=0.86291, warmup_bias_lr=0.0953, box=0.06605, cls=0.49122, cls_pw=1.06226, obj=1.06038, obj_pw=1.07585, iou_t=0.2, anchor_t=4.54733, fl_gamma=0.0, hsv_h=0.017, hsv_s=0.82962, hsv_v=0.59323, degrees=0.0, translate=0.10263, scale=0.43454, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.18334\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=2.18334\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     21552  models.yolo.Detect                      [3, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20868624 parameters, 20868624 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00965) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00048), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels.cache... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 9.3/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels.cache... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9926: 100% 1000/1000 [00:03<00:00, 307.60it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.672/0.993-mean/best, past_thr=0.784-mean: 70,146, 206,263, 550,506, 537,574, 640,640, 657,636\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_hyper/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_hyper/exp2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/5      5.97G    0.05945    0.04824    0.03558         49        640: 100% 627/627 [05:13<00:00,  2.00it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/5      5.97G    0.03744    0.02464    0.03351         50        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/5      5.97G    0.03036    0.01953    0.03005         53        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/5      5.97G    0.02376    0.01737    0.02884         53        640:  13% 83/627 [00:40<03:40,  2.46it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code for YOLOv5m after hyperparameter tuning"
      ],
      "metadata": {
        "id": "DrKGBGAJv6Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data '/content/yolov5/burn-wound-classification-1/data.yaml' --img 640 --batch 16 --epochs 25 --weights yolov5m.pt --cache --hyp \"/content/drive/MyDrive/Yolov5m_hyper/exp2/hyp_evolve.yaml\" --project \"/content/drive/MyDrive/Yolov5m_result\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhU1FC6-FuOt",
        "outputId": "da17aa86-8e44-45fa-a905-c4bfe494740f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-08 13:46:06.987251: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-08 13:46:08.008230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=/content/yolov5/burn-wound-classification-1/data.yaml, hyp=/content/drive/MyDrive/Yolov5m_hyper/exp2/hyp_evolve.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/Yolov5m_result, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-134-g23c4923 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00999, lrf=0.01003, momentum=0.93679, weight_decay=0.00054, warmup_epochs=2.9483, warmup_momentum=0.81634, warmup_bias_lr=0.10049, box=0.05095, cls=0.49401, cls_pw=0.98947, obj=1.0085, obj_pw=1.0054, iou_t=0.2, anchor_t=4.091, fl_gamma=0.0, hsv_h=0.01505, hsv_s=0.67744, hsv_v=0.3905, degrees=0.0, translate=0.09547, scale=0.48973, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.9847, mixup=0.0, copy_paste=0.0, anchors=3.1527\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Yolov5m_result', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n",
            "100% 40.8M/40.8M [00:00<00:00, 101MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "Overriding model.yaml anchors with anchors=3.1527\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00999) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.00054), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:05<00:00, 1939.25it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/burn-wound-classification-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 10.4/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:01<00:00, 412.99it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/burn-wound-classification-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB ram): 100% 457/457 [00:03<00:00, 115.11it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 10032 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ switching strategies from kmeans to random init\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9946: 100% 1000/1000 [00:02<00:00, 442.89it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 7.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.538/0.995-mean/best, past_thr=0.656-mean: 64,70, 91,162, 174,253, 255,264, 324,381, 489,490, 432,713, 632,623, 640,640\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_result/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_result/exp\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/24      6.15G    0.04639    0.04089    0.03469         43        640: 100% 627/627 [05:28<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.05it/s]\n",
            "                   all        457        457      0.325      0.983      0.495       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/24      7.37G    0.03025    0.02133    0.03192         49        640: 100% 627/627 [05:21<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.31it/s]\n",
            "                   all        457        457      0.538      0.797      0.631      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/24      7.38G    0.02554    0.01803    0.02872         53        640: 100% 627/627 [05:18<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.22it/s]\n",
            "                   all        457        457      0.506      0.748      0.639      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/24      7.38G    0.02053    0.01632    0.02767         44        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.36it/s]\n",
            "                   all        457        457      0.371      0.922      0.448      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/24      7.38G    0.01632    0.01437    0.02691         53        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.35it/s]\n",
            "                   all        457        457      0.448      0.889      0.625      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/24      7.38G    0.01412    0.01316    0.02607         46        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.39it/s]\n",
            "                   all        457        457      0.669      0.739      0.735       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/24      7.38G     0.0126    0.01229    0.02522         47        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.14it/s]\n",
            "                   all        457        457      0.392      0.889      0.508      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/24      7.38G    0.01129    0.01173    0.02504         39        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.17it/s]\n",
            "                   all        457        457      0.607      0.734      0.701      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/24      7.38G    0.01031    0.01125    0.02456         49        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.24it/s]\n",
            "                   all        457        457      0.536      0.839      0.697      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/24      7.38G   0.009532    0.01034    0.02376         51        640: 100% 627/627 [05:12<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.23it/s]\n",
            "                   all        457        457      0.693      0.748      0.768      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/24      7.38G   0.008687    0.01025    0.02346         53        640: 100% 627/627 [05:13<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.17it/s]\n",
            "                   all        457        457      0.584      0.773      0.745      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/24      7.38G   0.007944   0.009656    0.02343         49        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.20it/s]\n",
            "                   all        457        457      0.566      0.795      0.737      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/24      7.38G   0.007501   0.009248    0.02266         48        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.21it/s]\n",
            "                   all        457        457      0.621      0.791      0.758      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/24      7.38G   0.007033   0.009042    0.02237         48        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.30it/s]\n",
            "                   all        457        457       0.63      0.776      0.772      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/24      7.38G   0.006609     0.0086    0.02204         52        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.32it/s]\n",
            "                   all        457        457      0.574      0.764      0.731      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/24      7.38G   0.006032    0.00836    0.02154         52        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.34it/s]\n",
            "                   all        457        457      0.613      0.815      0.779      0.772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/24      7.38G   0.005644   0.008105    0.02113         47        640: 100% 627/627 [05:11<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.46it/s]\n",
            "                   all        457        457      0.625       0.81      0.784       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/24      7.38G   0.005195   0.007729    0.02098         52        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.47it/s]\n",
            "                   all        457        457      0.699      0.737       0.79      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/24      7.38G   0.004711   0.007439    0.02016         48        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.31it/s]\n",
            "                   all        457        457      0.628      0.824       0.77      0.768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/24      7.38G   0.004324   0.007149    0.01994         40        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.18it/s]\n",
            "                   all        457        457      0.767      0.752      0.804      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/24      7.38G   0.003935   0.006888    0.01924         49        640: 100% 627/627 [05:07<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.30it/s]\n",
            "                   all        457        457      0.732      0.787      0.817      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/24      7.38G   0.003497   0.006686    0.01933         46        640: 100% 627/627 [05:08<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.31it/s]\n",
            "                   all        457        457      0.664      0.793      0.815      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/24      7.38G   0.003162   0.006559    0.01852         45        640: 100% 627/627 [05:09<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.31it/s]\n",
            "                   all        457        457      0.677      0.805       0.81      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/24      7.38G   0.002804   0.006174    0.01799         47        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.32it/s]\n",
            "                   all        457        457      0.674      0.768      0.813       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/24      7.38G   0.002539   0.005925    0.01744         47        640: 100% 627/627 [05:10<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.38it/s]\n",
            "                   all        457        457      0.713      0.777      0.803        0.8\n",
            "\n",
            "25 epochs completed in 2.217 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Yolov5m_result/exp/weights/last.pt, 42.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Yolov5m_result/exp/weights/best.pt, 42.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Yolov5m_result/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:08<00:00,  1.72it/s]\n",
            "                   all        457        457      0.664      0.794      0.815      0.811\n",
            "                     0        457        170      0.639      0.859      0.821      0.819\n",
            "                     1        457        221      0.707      0.766      0.822      0.818\n",
            "                     2        457         66      0.645      0.758      0.801      0.796\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_result/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code for YOLOv5m before hyperparameter tuning"
      ],
      "metadata": {
        "id": "gF39gNtwwBxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data '/content/yolov5/burn-wound-classification-1/data.yaml' --img 640 --batch 16 --epochs 25 --weights yolov5m.pt --cache --save-period 5 --project \"/content/drive/MyDrive/Yolov5m_normal\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V98mGdifSpk",
        "outputId": "bf585978-f59f-42b8-a93f-b84febd143af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=/content/yolov5/burn-wound-classification-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/Yolov5m_normal, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=5, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-151-g3e14883 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Yolov5m_normal', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n",
            "100% 40.8M/40.8M [00:00<00:00, 213MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 475/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/train/labels... 10032 images, 0 backgrounds, 0 corrupt: 100% 10032/10032 [00:05<00:00, 1791.40it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/burn-wound-classification-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.5GB RAM required, 10.4/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/burn-wound-classification-1/valid/labels... 457 images, 0 backgrounds, 0 corrupt: 100% 457/457 [00:00<00:00, 607.12it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/burn-wound-classification-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB ram): 100% 457/457 [00:02<00:00, 164.41it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.40 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to /content/drive/MyDrive/Yolov5m_normal/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Yolov5m_normal/exp\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/24      6.15G    0.02653    0.01592    0.02356         49        640: 100% 627/627 [05:50<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:08<00:00,  1.70it/s]\n",
            "                   all        457        457       0.44      0.767      0.501      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/24      7.38G    0.01465   0.008013    0.02079         50        640: 100% 627/627 [05:45<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.38it/s]\n",
            "                   all        457        457      0.364      0.839      0.454       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/24      7.38G    0.01284   0.007066    0.01983         53        640: 100% 627/627 [05:39<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.25it/s]\n",
            "                   all        457        457      0.549      0.694      0.672       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/24      7.38G    0.01005   0.006414    0.01992         44        640: 100% 627/627 [05:36<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.05it/s]\n",
            "                   all        457        457      0.465       0.77      0.614      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/24      7.38G   0.008309   0.005794    0.01945         44        640: 100% 627/627 [05:37<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.04it/s]\n",
            "                   all        457        457      0.641      0.665       0.71      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/24      7.38G   0.006871   0.005231    0.01868         52        640: 100% 627/627 [05:38<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.31it/s]\n",
            "                   all        457        457       0.45      0.832      0.671      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/24      7.38G   0.006215   0.004802    0.01841         52        640: 100% 627/627 [05:41<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.23it/s]\n",
            "                   all        457        457      0.518      0.829      0.732      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/24      7.38G   0.005737   0.004569    0.01832         48        640: 100% 627/627 [05:38<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.12it/s]\n",
            "                   all        457        457      0.588      0.747      0.735      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/24      7.38G   0.005377   0.004427    0.01813         45        640: 100% 627/627 [05:40<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.14it/s]\n",
            "                   all        457        457      0.611      0.717      0.735      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/24      7.38G   0.004894   0.004218    0.01771         42        640: 100% 627/627 [05:39<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.34it/s]\n",
            "                   all        457        457      0.586      0.728      0.725      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/24      7.38G   0.004763   0.004131    0.01781         45        640: 100% 627/627 [05:39<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.12it/s]\n",
            "                   all        457        457      0.638      0.774      0.752      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/24      7.38G   0.004333   0.003949    0.01734         53        640: 100% 627/627 [05:40<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.30it/s]\n",
            "                   all        457        457      0.592      0.798      0.759      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/24      7.38G   0.004113   0.003895    0.01714         46        640: 100% 627/627 [05:40<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.39it/s]\n",
            "                   all        457        457       0.65      0.758      0.746      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/24      7.38G   0.003894   0.003768    0.01684         52        640: 100% 627/627 [05:39<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.09it/s]\n",
            "                   all        457        457      0.656      0.715       0.74      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/24      7.38G   0.003692   0.003643    0.01663         52        640: 100% 627/627 [05:41<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.25it/s]\n",
            "                   all        457        457      0.627       0.79      0.752      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/24      7.38G   0.003377   0.003495    0.01641         47        640: 100% 627/627 [05:40<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.42it/s]\n",
            "                   all        457        457      0.654      0.745      0.749      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/24      7.38G   0.003293   0.003422    0.01644         52        640: 100% 627/627 [05:41<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.06it/s]\n",
            "                   all        457        457      0.652      0.755      0.751      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/24      7.38G   0.002954   0.003299    0.01607         46        640: 100% 627/627 [05:43<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.43it/s]\n",
            "                   all        457        457      0.604      0.787      0.742      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/24      7.38G   0.002857   0.003219    0.01576         50        640: 100% 627/627 [05:42<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.33it/s]\n",
            "                   all        457        457      0.622      0.746      0.747      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/24      7.38G   0.002687   0.003068    0.01567         45        640: 100% 627/627 [05:42<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.10it/s]\n",
            "                   all        457        457      0.649      0.764      0.767      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/24      7.38G   0.002435   0.003001    0.01529         50        640: 100% 627/627 [05:43<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.37it/s]\n",
            "                   all        457        457      0.638      0.804      0.775       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/24      7.38G   0.002276   0.002884    0.01549         48        640: 100% 627/627 [05:40<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.20it/s]\n",
            "                   all        457        457      0.669      0.782      0.795      0.774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/24      7.38G    0.00213   0.002846    0.01528         51        640: 100% 627/627 [05:41<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  2.01it/s]\n",
            "                   all        457        457      0.656       0.79      0.774       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/24      7.38G   0.001969   0.002715    0.01483         47        640: 100% 627/627 [05:43<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:06<00:00,  2.42it/s]\n",
            "                   all        457        457      0.721      0.756      0.793      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/24      7.38G   0.001812   0.002607    0.01472         49        640: 100% 627/627 [05:43<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:07<00:00,  1.92it/s]\n",
            "                   all        457        457      0.657      0.798      0.776      0.769\n",
            "\n",
            "25 epochs completed in 2.427 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Yolov5m_normal/exp/weights/last.pt, 42.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Yolov5m_normal/exp/weights/best.pt, 42.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Yolov5m_normal/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 15/15 [00:10<00:00,  1.42it/s]\n",
            "                   all        457        457      0.721      0.756      0.793      0.784\n",
            "                     0        457        170      0.764      0.761       0.83      0.826\n",
            "                     1        457        221      0.723      0.783      0.819      0.801\n",
            "                     2        457         66      0.675      0.724      0.729      0.725\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Yolov5m_normal/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/skinburn_100_epoch/weights/best.pt source=/content/drive/MyDrive/MLTrainingModel/SplitDataset/TestingImages/ conf=0.15 save=True\n"
      ],
      "metadata": {
        "id": "NmvIiuBvcXYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}